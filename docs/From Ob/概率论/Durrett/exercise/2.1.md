---
UID: 20241008160815 
aliases: 
tags: 
source: 
cssclass: 
created: 2024-10-08
---

## ✍内容
![[2.1-20241008.png]]
$\displaystyle \forall A_{i}\in \mathcal{R},P(X\in A)=\int _{A}f(x) \, dx=\int _{A}g_{1}(x_{1})\dots g_{n}(x_{n}) \, dx\overset{ fubini }{ = }\int _{A_{1}}g_{1}(x_{1}) \, dx_{1}\dots \int _{A_{n}}g_{n}(x_{n}) \, dx_{n}$, but $\displaystyle g_{m}$ are not assumed to be probability densities. So we may not have $\displaystyle \int _{A_{i}}g_{i}(x_{i}) \, dx_{i}=P(X_{i}\in A_{i})$. However, we know that $\displaystyle 1=P(X\in \mathcal{R}^{n})=\int _{\mathcal{R}^{n}}f(x) \, dx=\int _{\mathcal{R}}g_{1}(x_{1}) \, dx_{1}\dots \int _{\mathcal{R}}g_{n}(x_{n}) \, dx_{n}$. 
$$
\begin{aligned}
P(X_{1}\in A_{1}) & =P(X_{1}\in A_{1},X_{2}\in \mathcal{R},\dots,X_{n}\in \mathcal{R}) =P(X\in A\times \mathcal{R}^{n-1}) \\
 & =\int _{A_{1}}g_{1}(x_{1}) \, dx_{1}\int _{\mathcal{R}}g_{2}(x_{2}) \, dx_{2} \dots \int _{\mathcal{R}}g_{n}(x_{n}) \, dx_{n}   \\
 & =\frac{\int _{A_{1}}g_{1}(x_{1}) \, dx_{1}}{\int _{\mathcal{R}}g_{1}(x_{1}) \, dx_{1} } 
\end{aligned}
$$
So $\displaystyle \prod_{i=1}^{n}P(X_{i}\in A_{i})=\prod_{i=1}^{n}\frac{\int _{A_{1}}g_{1}(x_{1}) \, dx_{1}}{\int _{\mathcal{R}}g_{1}(x_{1}) \, dx_{1}}=\prod_{i=1}^{n}\int _{A_{i}}g_{i}(x_{i}) \, dx_{i}=P(X\in A)$, then $\displaystyle X_{1},X_{2},\dots,X_{n}$ are independent.
![[1-2.1-20241008.png]]
> Exercise 1.3.1:
> If $\displaystyle \mathcal{A}$ generates $\displaystyle \mathcal{S}$, then $\displaystyle X^{-1}(\mathcal{A})=\{ \{ X\in A \}:A\in \mathcal{A} \}$ generates $\displaystyle \sigma(X)=\{ \{ X\in B \}:B\in \mathcal{S} \}$.

Let $\displaystyle \mathcal{A}_{i}$ be sets of the form $\displaystyle \{ X_{i}=x_{i} \}$ and includes $\displaystyle \varnothing$. So $\displaystyle \mathcal{A}_{i}$ is a $\displaystyle \pi$ -system. 
> $\displaystyle \sigma(X)=\{ \{ X\in B \}:B\in \mathcal{S} \}$ is called the $\displaystyle \sigma$ -field generated by $X$.

> If $\displaystyle \mathcal{S}$ is a $\displaystyle \sigma$ -field, then $\displaystyle \{ \{ X\in B \}:B\in \mathcal{S} \}$ is a $\displaystyle \sigma$ -field.

Just prove it like Theorem 2.1.8.

![[2-2.1-20241008.png]]
Just prove it directly.

![[3-2.1-20241008.png]]
> Two random variables $X$ and $Y$ with $\displaystyle EX^{2},EY^{2}<\infty$ that have $\displaystyle EXY=EXEY$ are said to be **uncorrelated**.

$\displaystyle EXY=\int _{\Omega}\sin(2\pi nx)\sin(2\pi mx) \, dx=0=EXEY,\forall m\neq n$. So they are uncorrelated.
>Two random variables $X$ and $Y$ are called **independent** if for all $\displaystyle C, D\in \Omega$, $\displaystyle P(X\in C,Y\in D)=P(X\in C)P(Y\in D)$. That is, the event $\displaystyle \{ X\in A \},\{ Y\in B \}$ are independent.

> [!NOTE]
>  I am not sure that this might be right, but I put $\displaystyle A_{n}=[0,1],\forall n$, and find that $\displaystyle P(X_{n}\in A_{n},\forall n)\sim\frac{1}{2n},\prod_{n\geq1}P(X_{n}\in A_{n})\sim\frac{1}{2^{n}}$.


![[4-2.1-20241008.png]]
(i)
Using Theorem 2.1.12 gives
$$
P(X+Y=0)=\iint \mathbb{1}_{(x+y=0)}\mu(dx)\nu(dy)=\sum_{y}\mu(\{ -y \})\nu(\{ y \})
$$
(ii)
.....

![[5-2.1-20241008.png]]
> The definition is that $\displaystyle \forall A, B\in \mathcal{R}$, we have $\displaystyle P(X\in A,Y\in B)=P(X\in A)P(Y\in B)$

It suffices to show that $\displaystyle P(f(X)\in A,g(Y)\in B)=P(f(X)\in A)P(g(Y)\in B)$. So what's the relationship between $\displaystyle f (X)\in A$ and $\displaystyle X\in A$? 
$\displaystyle f (X)\in A\Rightarrow X\in f^{-1}(A)$, since $f$ is a measurable function, the preimage of open sets are measurable sets. 
[[Rudin.  Real and Complex Analysis(2).pdf]]




