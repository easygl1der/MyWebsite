---
UID: 20241013153610 
aliases: 
tags: 
source: 
cssclass: 
created: 2024-10-13
---

## ✍内容
![[2.2-20241013.png]]

![[4-2.2-20241013.png]]
类似上述定理的证明：
$$
E(S_{n}/n-ES_{n}/n)^{2}=Var(S_{n}/n)=\frac{1}{n^{2}}Var(S_{n})=\frac{Var(X_{1})+\dots+Var(X_{n})}{n^{2}}
$$
于是
$$
\lim_{ n \to \infty } E(S_{n}/n-ES_{n}/n)^{2}=\lim_{ n \to \infty } \frac{Var(X_{1})+\dots+Var(X_{n})}{n^{2}}=\lim_{ n \to \infty } \frac{Var(X_{n})}{2n-1}=0
$$
故 $\displaystyle S_{n}/n\to \mu$ in $\displaystyle L^{2}$，由 Lemma 2. $\displaystyle 2.2$ 就有，$\displaystyle S_{n}/n\to \mu$ in probability.
![[5-2.2-20241013.png]]

---

![[1-2.2-20241013.png]]
$\displaystyle \forall \epsilon>0,\exists K>0,\text{s.t. }\forall k\geq K,r(k)\leq\epsilon$, by Cauchy-Schwarz inequality, $\displaystyle EX_{i}X_{j}\leq(EX_{i}^{2}EX_{j}^{2})^{1/2}\leq r(0)$. Break the sum into $\displaystyle \lvert i-j \rvert\leq K$ and $\displaystyle \lvert i-j \rvert> K$, then
$$
ES_{n}^{2}=\sum_{1\leq i,j\leq n}EX_{i}X_{j}\leq (2K+1)nr(0)+n^{2}\epsilon
$$
Hence, $\displaystyle \limsup_{ n \to \infty }E(S_{n}/n)^{2}\leq\epsilon$. Since $\displaystyle \epsilon$ is arbitray, we have $\displaystyle E(S_{n}/n)^{2}=0$, i.e.$\displaystyle S_{n}/n\to n$ in $\displaystyle L^{2}$, thus in probability.
![[2-2.2-20241013.png]]
$\displaystyle U_{i}$ independent, then $\displaystyle f(U_{i})$ independent, with $\displaystyle E\lvert f(U_{i}) \rvert=\int \lvert f(U_{i}) \rvert \, dP=\int_{0}^{1} \lvert f(U_{i}(x)) \rvert \, dx=\int_{0}^{1} \lvert f(x) \rvert \, dx<\infty$. By the $\displaystyle L^{2}$ weak law, $\displaystyle I_{n}\to I=\int_{0}^{1} f \, dx=Ef(U_{i}),\forall i$ in $\displaystyle L^{2}$ and probability.
...


![[3-2.2-20241013.png]]

